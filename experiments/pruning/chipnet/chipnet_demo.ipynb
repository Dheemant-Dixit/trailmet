{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7TLKHO9xfH3c2+Uq8lJys"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##**ChipNet**\n",
        "\n",
        "This notebook demonstrates the implementation of the paper - **ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations**\n",
        "\n",
        "Steps to train a baseline model and then compress it for a given budget are as follows: \n",
        "*   Load the YAML file.\n",
        "*   Load dataset and create dataloaders.\n",
        "*   Create ChipNet object and pass the parameters in the form of a dictionary.\n",
        "*   Pass the dataloaders into the compress_model method to obtain the compressed model.\n",
        "\n",
        "Since this is a demo notebook the number of epochs have been set to 1, 1 and 2 respectively for pretraining, pruning and finetuning respectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "iE3b83Z-nOMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from trailmet.models import ModelsFactory\n",
        "from trailmet.datasets.classification import DatasetFactory\n",
        "import yaml"
      ],
      "metadata": {
        "id": "sawZx2AaUrSb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"/content/trailmet/experiments/chipnet\""
      ],
      "metadata": {
        "id": "f1F3p74GUurK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the yaml file for the configurations."
      ],
      "metadata": {
        "id": "kumEj_KQoDa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "with open(os.path.join(root, \"resnet50_cifar100.yaml\"), 'r') as stream:\n",
        "    data_loaded = yaml.safe_load(stream)\n",
        "print(data_loaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gScM1VukUyUd",
        "outputId": "f39df67d-dcde-43ed-e149-f252093addca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'CHIPNET_ARGS': {'A': 10}, 'PRETRAIN': {'EPOCHS': 1}, 'PRUNE': {'EPOCHS': 1}, 'FINETUNE': {'EPOCHS': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the model."
      ],
      "metadata": {
        "id": "IA1AN-IzoK5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ModelsFactory.create_model('resnet50', 100, False, insize=32)"
      ],
      "metadata": {
        "id": "nB_iWiaeWUuZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the dataset."
      ],
      "metadata": {
        "id": "hb8NqjjFoNUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trailmet.datasets.classification import DatasetFactory\n",
        "data_root = \"/content/data_dir\""
      ],
      "metadata": {
        "id": "GgpDcVBVU0nM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir /content/data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPPq7RnSVo8C",
        "outputId": "770e4560-180e-4e0e-8d74-35c625b15a5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/data_dir’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "val_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "transforms1 = {\n",
        "    'train': train_transform, \n",
        "    'val': val_transform, \n",
        "    'test': test_transform}\n",
        "def train_target_transform(label):\n",
        "    return label\n",
        "\n",
        "def val_target_transform(label):\n",
        "    return label\n",
        "\n",
        "def test_target_transform(label):\n",
        "    return label\n",
        "\n",
        "target_transforms = {\n",
        "    'train': None, \n",
        "    'val': None, \n",
        "    'test': None}\n",
        "\n",
        "\n",
        "cifar_dataset = DatasetFactory.create_dataset(name = 'CIFAR100', \n",
        "                                        root = data_root,\n",
        "                                        split_types = ['train', 'val', 'test'],\n",
        "                                        val_fraction = 0.2,\n",
        "                                        transform = transforms1,\n",
        "                                        target_transform = target_transforms\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osLzBsQeVwxw",
        "outputId": "31ab8c32-197b-4f28-9d24-ffd51c0cadef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the dataloaders."
      ],
      "metadata": {
        "id": "pYUC-GRxoTs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['train'], batch_size=64, \n",
        "        sampler=cifar_dataset['train_sampler'],\n",
        "        num_workers=0\n",
        "    )\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['val'], batch_size=64, \n",
        "        sampler=cifar_dataset['val_sampler'],\n",
        "        num_workers=0\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['test'], batch_size=64, \n",
        "        sampler=cifar_dataset['test_sampler'],\n",
        "        num_workers=0\n",
        "    )"
      ],
      "metadata": {
        "id": "LvP7d7IYV1q_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the method's object followed by compression"
      ],
      "metadata": {
        "id": "jxxv1kvnoZUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trailmet.algorithms.prune.chipnet import ChipNet"
      ],
      "metadata": {
        "id": "7LK8Pw3lWKVA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = ChipNet(model, {'train': train_loader, 'val': val_loader, 'test': test_loader}, **data_loaded)"
      ],
      "metadata": {
        "id": "gRxxsYSZWMpQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.compress_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpsqRsKgWPtj",
        "outputId": "0812323c-d3e9-413f-8cf6-3944715b9da5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:56<00:00, 11.13it/s, loss=4.49]\n",
            "100%|██████████| 157/157 [00:04<00:00, 31.72it/s, acc1=8.03, acc5=28, loss=4.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving model**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:05<00:00, 29.40it/s, acc1=8.35, acc5=28.6, loss=4.33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 8.349920382165605 | Valid Accuracy: 8.031449044585987\n",
            "preparing model for pruning\n",
            "Starting epoch 1 / 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:56<00:00,  5.36it/s, loss=7.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 / 1] Validation before pruning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:12<00:00, 12.19it/s, acc1=19.5, acc5=48.7, loss=4.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 / 1] Validation after pruning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:09<00:00, 15.98it/s, acc1=1.01, acc5=5.21, loss=4.89e+5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed beta to 1.02 changed gamma to 2.8284271247461903\n",
            "**Saving checkpoint**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:00<00:00, 10.29it/s, loss=3.03]\n",
            "100%|██████████| 157/157 [00:07<00:00, 22.39it/s, acc1=20.8, acc5=50.3, loss=3.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving model**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:00<00:00, 10.35it/s, loss=2.77]\n",
            "100%|██████████| 157/157 [00:07<00:00, 22.15it/s, acc1=26.9, acc5=57.9, loss=2.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving model**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:06<00:00, 23.59it/s, acc1=27.7, acc5=58.8, loss=2.87]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 27.726910828025478 | Valid Accuracy: 26.930732484076433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}