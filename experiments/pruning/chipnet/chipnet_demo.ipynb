{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNYHtfi466iTgScQQ0I9MP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##**ChipNet**\n",
        "\n",
        "This notebook demonstrates the implementation of the paper - **ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations**\n",
        "\n",
        "Steps to train a baseline model and then compress it for a given budget are as follows: \n",
        "*   Load the YAML file.\n",
        "*   Load dataset and create dataloaders.\n",
        "*   Create ChipNet object and pass the parameters in the form of a dictionary.\n",
        "*   Pass the dataloaders into the compress_model method to obtain the compressed model.\n",
        "\n",
        "Since this is a demo notebook the number of epochs have been set to 1, 1 and 2 respectively for pretraining, pruning and finetuning respectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "iE3b83Z-nOMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from trailmet.models import ModelsFactory\n",
        "from trailmet.datasets.classification import DatasetFactory\n",
        "import yaml"
      ],
      "metadata": {
        "id": "sawZx2AaUrSb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"/content/trailmet/experiments/pruning/chipnet\""
      ],
      "metadata": {
        "id": "f1F3p74GUurK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the yaml file for the configurations."
      ],
      "metadata": {
        "id": "kumEj_KQoDa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "with open(os.path.join(root, \"chipnet.yaml\"), 'r') as stream:\n",
        "    data_loaded = yaml.safe_load(stream)\n",
        "print(data_loaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gScM1VukUyUd",
        "outputId": "532c5ad8-838e-499f-869a-10bb5a55b207"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'CHIPNET_ARGS': {'BUDGET_TYPE': 'channel_ratio', 'TARGET_BUDGET': 0.5, 'BUDGET_LOSS_WEIGHTAGE': 30, 'CRISPNESS_LOSS_WEIGHTAGE': 10, 'BETA_INCREMENT': 5, 'GAMMA_INCREMENT': 2, 'STEEPNESS': 100}, 'PRETRAIN': {'EPOCHS': 1, 'TEST_ONLY': False, 'OPTIMIZER': 'SGD', 'LR': 0.05, 'SCHEDULER_TYPE': 1, 'WEIGHT_DECAY': 0.001}, 'PRUNE': {'EPOCHS': 1, 'TEST_ONLY': False, 'OPTIMIZER': 'SGD', 'LR': 0.05, 'WEIGHT_DECAY': 0.001}, 'FINETUNE': {'EPOCHS': 2, 'TEST_ONLY': False, 'OPTIMIZER': 'SGD', 'LR': 0.05, 'SCHEDULER_TYPE': 1, 'WEIGHT_DECAY': 0.001}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the model."
      ],
      "metadata": {
        "id": "IA1AN-IzoK5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ModelsFactory.create_model('resnet50', 100, False, insize=32)"
      ],
      "metadata": {
        "id": "nB_iWiaeWUuZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the dataset."
      ],
      "metadata": {
        "id": "hb8NqjjFoNUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trailmet.datasets.classification import DatasetFactory\n",
        "data_root = \"/content/data_dir\""
      ],
      "metadata": {
        "id": "GgpDcVBVU0nM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir /content/data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPPq7RnSVo8C",
        "outputId": "a161435b-2d15-4aa0-f597-287468a6a8fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/data_dir’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "val_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "transforms1 = {\n",
        "    'train': train_transform, \n",
        "    'val': val_transform, \n",
        "    'test': test_transform}\n",
        "def train_target_transform(label):\n",
        "    return label\n",
        "\n",
        "def val_target_transform(label):\n",
        "    return label\n",
        "\n",
        "def test_target_transform(label):\n",
        "    return label\n",
        "\n",
        "target_transforms = {\n",
        "    'train': None, \n",
        "    'val': None, \n",
        "    'test': None}\n",
        "\n",
        "\n",
        "cifar_dataset = DatasetFactory.create_dataset(name = 'CIFAR100', \n",
        "                                        root = data_root,\n",
        "                                        split_types = ['train', 'val', 'test'],\n",
        "                                        val_fraction = 0.2,\n",
        "                                        transform = transforms1,\n",
        "                                        target_transform = target_transforms\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osLzBsQeVwxw",
        "outputId": "4d32f266-58c2-41da-e698-b3eb91a2db1c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the dataloaders."
      ],
      "metadata": {
        "id": "pYUC-GRxoTs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['train'], batch_size=64, \n",
        "        sampler=cifar_dataset['train_sampler'],\n",
        "        num_workers=0\n",
        "    )\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['val'], batch_size=64, \n",
        "        sampler=cifar_dataset['val_sampler'],\n",
        "        num_workers=0\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['test'], batch_size=64, \n",
        "        sampler=cifar_dataset['test_sampler'],\n",
        "        num_workers=0\n",
        "    )"
      ],
      "metadata": {
        "id": "LvP7d7IYV1q_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the method's object followed by compression"
      ],
      "metadata": {
        "id": "jxxv1kvnoZUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trailmet.algorithms.prune.chipnet import ChipNet"
      ],
      "metadata": {
        "id": "7LK8Pw3lWKVA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = ChipNet(model, {'train': train_loader, 'val': val_loader, 'test': test_loader}, **data_loaded)"
      ],
      "metadata": {
        "id": "gRxxsYSZWMpQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.compress_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpsqRsKgWPtj",
        "outputId": "30b2b27a-007f-4aad-f685-8eb572b4a4c3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=4.43]\n",
            "100%|██████████| 157/157 [00:05<00:00, 31.18it/s, acc1=10.2, acc5=32.7, loss=3.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving model**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:05<00:00, 28.25it/s, acc1=10.3, acc5=32.1, loss=3.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 10.300557324840764 | Valid Accuracy: 10.161226114649681\n",
            "preparing model for pruning\n",
            "Starting epoch 1 / 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [02:35<00:00,  4.02it/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 / 1] Validation before pruning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:17<00:00,  9.23it/s, acc1=3.28, acc5=15.4, loss=4.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 / 1] Validation after pruning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:12<00:00, 12.88it/s, acc1=0.995, acc5=5.47, loss=4.83e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed beta to 1.02 changed gamma to 2.8284271247461903\n",
            "**Saving checkpoint**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:00<00:00, 10.30it/s, loss=4.35]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.34it/s, acc1=3.77, acc5=16, loss=4.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving model**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:00<00:00, 10.37it/s, loss=4.27]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.92it/s, acc1=4.04, acc5=16.6, loss=4.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving model**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:06<00:00, 22.58it/s, acc1=4.1, acc5=16.4, loss=4.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 4.100318471337579 | Valid Accuracy: 4.040605095541402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}