{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "498871cf",
   "metadata": {},
   "source": [
    "## LAPQ\n",
    "This notebook demonstrates the implimentation of the paper [Loss Aware Post-training Quantization](https://arxiv.org/abs/1911.07190)\n",
    "\n",
    "### Steps to quantize the pretrained model\n",
    "- Load the dataset and create dataloader. A subset of training data is used for calibration.\n",
    "- Load the pretrained full precision model.\n",
    "- Load the configurations from the YAML file.\n",
    "- Create a `LAPQ` object and pass the full precision model, dataloaders and configurations.\n",
    "- Quantize the model by calling the `compress_model` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafbd1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417e9692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py117/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from trailmet.datasets.classification import DatasetFactory\n",
    "from trailmet.models import ModelsFactory\n",
    "from trailmet.algorithms import quantize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c67e2359",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64a12f9a",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8c6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*stats, inplace=True),\n",
    "    ]\n",
    ")\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(*stats)]\n",
    ")\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(*stats)]\n",
    ")\n",
    "\n",
    "input_transforms = {\n",
    "    \"train\": train_transform,\n",
    "    \"val\": val_transform,\n",
    "    \"test\": test_transform,\n",
    "}\n",
    "\n",
    "target_transforms = {\"train\": None, \"val\": None, \"test\": None}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c41f2b1",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b377f3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train samples:  40000\n",
      "Val samples:  10000\n",
      "Test samples:  10000\n"
     ]
    }
   ],
   "source": [
    "cifar100_dataset = DatasetFactory.create_dataset(\n",
    "    name=\"CIFAR100\",\n",
    "    root=\"./data\",\n",
    "    split_types=[\"train\", \"val\", \"test\"],\n",
    "    val_fraction=0.2,\n",
    "    transform=input_transforms,\n",
    "    target_transform=target_transforms,\n",
    ")\n",
    "\n",
    "# getting the size of the different splits\n",
    "print(\"Train samples: \", cifar100_dataset[\"info\"][\"train_size\"])\n",
    "print(\"Val samples: \", cifar100_dataset[\"info\"][\"val_size\"])\n",
    "print(\"Test samples: \", cifar100_dataset[\"info\"][\"test_size\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eec91853",
   "metadata": {},
   "source": [
    "### Define Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "464c2e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training batches:  313\n",
      "No. of validation batches:  79\n",
      "No. of test batches:  79\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    cifar100_dataset[\"train\"],\n",
    "    batch_size=128,\n",
    "    sampler=cifar100_dataset[\"train_sampler\"],\n",
    "    num_workers=2,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    cifar100_dataset[\"val\"],\n",
    "    batch_size=128,\n",
    "    sampler=cifar100_dataset[\"val_sampler\"],\n",
    "    num_workers=2,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    cifar100_dataset[\"test\"],\n",
    "    batch_size=128,\n",
    "    sampler=cifar100_dataset[\"test_sampler\"],\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader, \"test\": test_loader}\n",
    "\n",
    "print(\"No. of training batches: \", len(dataloaders[\"train\"]))\n",
    "print(\"No. of validation batches: \", len(dataloaders[\"val\"]))\n",
    "print(\"No. of test batches: \", len(dataloaders[\"test\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85812739",
   "metadata": {},
   "source": [
    "### Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4db07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "res50_model = ModelsFactory.create_model(\n",
    "    name=\"resnet50\", num_classes=100, pretrained=False, insize=32\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ca3e796",
   "metadata": {},
   "source": [
    "### Load Method Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9625ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPU_ID': 0,\n",
       " 'SEED': 42,\n",
       " 'W_BITS': 4,\n",
       " 'A_BITS': 8,\n",
       " 'ACT_QUANT': True,\n",
       " 'CALIB_BATCHES': 4,\n",
       " 'MAX_ITER': 1000,\n",
       " 'MAX_FEV': 1000,\n",
       " 'VERBOSE': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./lapq_config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    kwargs = config[\"GENERAL\"]\n",
    "\n",
    "kwargs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87e6c554",
   "metadata": {},
   "source": [
    "### Quantization Method: BRECQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21d5073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Using seed: 42 and device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manimesh-007\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/animesh_trailmet/experiments/quantization/LAPQ/wandb/run-20230625_230422-w4sdlkw4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/animesh-007/Trailmet%20LAPQ/runs/w4sdlkw4' target=\"_blank\">CIFAR100_8_Jun-25_23:04:20</a></strong> to <a href='https://wandb.ai/animesh-007/Trailmet%20LAPQ' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/animesh-007/Trailmet%20LAPQ' target=\"_blank\">https://wandb.ai/animesh-007/Trailmet%20LAPQ</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/animesh-007/Trailmet%20LAPQ/runs/w4sdlkw4' target=\"_blank\">https://wandb.ai/animesh-007/Trailmet%20LAPQ/runs/w4sdlkw4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing pretrained model before quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating network (79 / 79 Steps) (batch time=0.01544s) (loss=9.17796) (top1=0.00000) (top5=0.00000): 100%|| 79/79 [00:04<00:00, 17.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * acc@1 1.040 acc@5 5.190\n",
      "top-1 acc: 1.04%, top-5 acc: 5.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating network (79 / 79 Steps) (batch time=0.04852s) (loss=11.44887) (top1=0.00000) (top5=0.00000): 100%|| 79/79 [00:04<00:00, 17.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * acc@1 1.010 acc@5 5.040\n",
      "==> Quantization (W4A8) accuracy before LAPQ: 1.0100 | 5.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.30it/s, loss=9.16, p_val=4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> using p intr : 4.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating network (79 / 79 Steps) (batch time=0.04860s) (loss=9.68071) (top1=0.00000) (top5=0.00000): 100%|| 79/79 [00:04<00:00, 16.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * acc@1 0.960 acc@5 5.070\n",
      "==> Quantization (W4A8) accuracy before Optimization: 0.9600 | 5.0700\n",
      "==> Loss after LpNormQuantization: 9.4259\n",
      "==> Starting Powell Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:28<00:00,  4.80it/s, curr_loss=4.62, min_loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Layer-wise Scales :\n",
      " [-2.71854830e+00 -3.08051988e-01  9.95627994e-01  3.81617464e+00\n",
      " -9.40671566e-01 -3.61076604e+00 -1.81663796e+00  1.21657309e+00\n",
      "  1.91811575e+00  2.52682898e+00 -1.42890691e+00 -1.70284810e+00\n",
      "  3.04076019e+00 -1.71109412e+00 -4.41954680e-01 -2.75285367e-01\n",
      "  4.77568090e+00 -8.70588564e-01 -1.46963710e+01 -6.32294023e-01\n",
      " -1.39139490e+00  4.28594499e+00 -1.21911043e+02 -1.34789206e+00\n",
      "  1.03977837e+00  1.19332061e+01 -1.46906333e+01 -4.85501959e-01\n",
      "  1.23643283e+00  1.34744476e+01 -7.74482854e-01 -1.09169621e+00\n",
      "  3.03794852e-01  1.49893110e+01 -1.44991452e+00 -6.44897627e+00\n",
      " -9.93479876e-01  1.35904461e-01  2.40335316e+01  2.86178112e-01\n",
      "  9.66371353e-02  1.44008197e-01  2.28464613e+01  2.84444329e-01\n",
      "  9.55632382e-02  1.41487494e-01  3.59558318e+01  2.82226657e-01\n",
      "  9.38017642e-02  1.43612936e-01  5.25450935e+01  2.79624492e-01\n",
      "  9.47439224e-02  1.43324569e-01  1.15084450e+02  2.01696590e-01\n",
      "  6.74792528e-02  1.00485601e-01  9.49488449e+01  1.02076188e-01\n",
      "  2.02921063e-01  6.77159503e-02  1.01089455e-01  1.21774887e+02\n",
      "  2.03220874e-01  6.74693212e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating network (79 / 79 Steps) (batch time=0.04774s) (loss=4.62941) (top1=0.00000) (top5=0.00000): 100%|| 79/79 [00:04<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * acc@1 1.090 acc@5 4.920\n",
      "==> Full quantization (W4A8) accuracy: 1.0899999141693115\n"
     ]
    }
   ],
   "source": [
    "quantizer = quantize.lapq.LAPQ(res50_model, dataloaders, **kwargs)\n",
    "\n",
    "print(\"testing pretrained model before quantization\")\n",
    "_, acc1, acc5 = quantizer.test(\n",
    "    model=res50_model,\n",
    "    dataloader=dataloaders[\"test\"],\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    ")\n",
    "print(f\"top-1 acc: {acc1:.2f}%, top-5 acc: {acc5:.2f}%\")\n",
    "\n",
    "qmodel = quantizer.compress_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6edd9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing quantized model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating network (79 / 79 Steps) (batch time=0.05487s) (loss=4.62941) (top1=0.00000) (top5=0.00000): 100%|| 79/79 [00:04<00:00, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * acc@1 1.090 acc@5 4.920\n",
      "top-1 acc: 1.09%, top-5 acc: 4.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"testing quantized model\")\n",
    "_, acc1, acc5 = quantizer.test(\n",
    "    model=qmodel, dataloader=dataloaders[\"test\"], loss_fn=torch.nn.CrossEntropyLoss()\n",
    ")\n",
    "print(f\"top-1 acc: {acc1:.2f}%, top-5 acc: {acc5:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
