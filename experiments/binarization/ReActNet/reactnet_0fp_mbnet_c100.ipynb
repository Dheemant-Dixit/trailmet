{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5efb69",
   "metadata": {},
   "source": [
    "# ReActNet\n",
    "This notebook demonstrates the implementation of the ReActNet Paper\n",
    "# Steps to binarize the model\n",
    "- Load Dataset and DataLoader\n",
    "- Create the teacher model to be binarized\n",
    "- Load the configuration YAML file\n",
    "- create `ReActNet object` and pass the teacher model, dataloader, configuration\n",
    "- Binarize the model by using `compress_model` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "359a354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../../../\")\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from trailmet.models import ModelsFactory\n",
    "from trailmet.datasets.classification import DatasetFactory\n",
    "from trailmet.algorithms.binarize.utils import *\n",
    "from trailmet.algorithms.binarize.ReActNet import ReActNet\n",
    "from trailmet.models.models import models\n",
    "import torchvision\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0010fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41ae44e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GENERAL': {'DATASET': 'c100',\n",
       "  'BACKBONE': 'mobilenetv2',\n",
       "  'batch_size': 256,\n",
       "  'workers': 4,\n",
       "  'valid_size': 0.1,\n",
       "  'num_train': 0,\n",
       "  'num_classes': 100,\n",
       "  'insize': 32},\n",
       " 'ReActNet1_ARGS': {'batch_size': 256,\n",
       "  'epochs': 5,\n",
       "  'learning_rate': 0.0005,\n",
       "  'momentum': 0.9,\n",
       "  'weight_deacy': '1e-5',\n",
       "  'label_smooth': 0.1,\n",
       "  'save': './save_path_mbnet_cifar100_0fp/step1'},\n",
       " 'ReActNet2_ARGS': {'batch_size': 256,\n",
       "  'epochs': 5,\n",
       "  'learning_rate': 0.0005,\n",
       "  'momentum': 0.9,\n",
       "  'weight_deacy': 0,\n",
       "  'label_smooth': 0.1,\n",
       "  'save': './save_path_mbnet_cifar100_0fp/step2'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"./\"\n",
    "import os\n",
    "\n",
    "with open(os.path.join(root_dir, \"reactnet_cifar100.yaml\"), \"r\") as stream:\n",
    "    kwargs = yaml.safe_load(stream)\n",
    "dataset_args = kwargs[\"GENERAL\"]\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f74a9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(\"> SEEDING DONE\")\n",
    "\n",
    "\n",
    "set_seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88475e7b",
   "metadata": {},
   "source": [
    "# Defining the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f5e3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenetv2\"\n",
    "teacher = models.get_model(\"mobilenetv2\", \"full\", 100, 32)\n",
    "\n",
    "pret = torch.load(\n",
    "    \"/workspace/code/janhavi/ChipNet/weights/mobilenetv2_c100_pretrained.pth\",\n",
    "    map_location=\"cuda\",\n",
    ")\n",
    "pret = pret[\"state_dict\"]\n",
    "\n",
    "teacher.load_state_dict(pret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a3fa2",
   "metadata": {},
   "source": [
    "# Augmentation, Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "820356d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Augmentation\n",
    "crop_scale = 0.08\n",
    "lighting_param = 0.1\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(32, scale=(crop_scale, 1.0)),\n",
    "        Lighting(lighting_param),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "valid_transform = transforms.Compose(\n",
    "    [transforms.Resize(36), transforms.CenterCrop(32), transforms.ToTensor()]\n",
    ")\n",
    "test_transform = valid_transform\n",
    "\n",
    "input_transforms = {\n",
    "    \"train\": train_transform,\n",
    "    \"val\": valid_transform,\n",
    "    \"test\": test_transform,\n",
    "}\n",
    "\n",
    "target_transforms = {\"train\": None, \"val\": None, \"test\": None}\n",
    "\n",
    "# Create Dataset\n",
    "cifar100_dataset = DatasetFactory.create_dataset(\n",
    "    name=\"CIFAR100\",\n",
    "    root=root_dir,\n",
    "    split_types=[\"train\", \"val\", \"test\"],\n",
    "    val_fraction=0.15,\n",
    "    transform=input_transforms,\n",
    "    target_transform=target_transforms,\n",
    ")\n",
    "# Define DataLoaders\n",
    "train_loader100 = torch.utils.data.DataLoader(\n",
    "    cifar100_dataset[\"train\"],\n",
    "    batch_size=dataset_args[\"batch_size\"],\n",
    "    sampler=cifar100_dataset[\"train_sampler\"],\n",
    "    num_workers=dataset_args[\"workers\"],\n",
    ")\n",
    "val_loader100 = torch.utils.data.DataLoader(\n",
    "    cifar100_dataset[\"val\"],\n",
    "    batch_size=dataset_args[\"batch_size\"],\n",
    "    sampler=cifar100_dataset[\"val_sampler\"],\n",
    "    num_workers=dataset_args[\"workers\"],\n",
    ")\n",
    "test_loader100 = torch.utils.data.DataLoader(\n",
    "    cifar100_dataset[\"test\"],\n",
    "    batch_size=dataset_args[\"batch_size\"],\n",
    "    sampler=cifar100_dataset[\"test_sampler\"],\n",
    "    num_workers=dataset_args[\"workers\"],\n",
    ")\n",
    "\n",
    "dataloaders = {\"train\": train_loader100, \"val\": val_loader100, \"test\": test_loader100}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2068e6",
   "metadata": {},
   "source": [
    "# ReActNet Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd4fa846",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ReActNet(teacher, model_name, dataloaders, num_fp=0, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c676cd6",
   "metadata": {},
   "source": [
    "# Binarizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df5e6889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-1 Training with activations binarized for 5 epochs\n",
      "\n",
      "EPOCH-0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 30/30 [00:01<00:00, 18.63it/s, acc1=0.99, acc5=4.76, loss=4.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.607090417704863\n",
      "Top-1 Train Accuracy-1.0141176470588236\n",
      "Top-5 Train Accuracy-4.863529411764706\n",
      "Validation Accuracy-0.9895833333333334\n",
      "Validation Loss-4.605341053009033\n",
      "EPOCH-1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████| 30/30 [00:01<00:00, 17.82it/s, acc1=0.981, acc5=5.6, loss=4.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.605135306952981\n",
      "Top-1 Train Accuracy-0.9129411764705883\n",
      "Top-5 Train Accuracy-4.83764705882353\n",
      "Validation Accuracy-0.9813596487045289\n",
      "Validation Loss-4.605096832911173\n",
      "EPOCH-2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████| 30/30 [00:01<00:00, 16.86it/s, acc1=1.08, acc5=4.96, loss=4.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.605053903377757\n",
      "Top-1 Train Accuracy-1.0023529411764707\n",
      "Top-5 Train Accuracy-4.936470588235294\n",
      "Validation Accuracy-1.0807291666666667\n",
      "Validation Loss-4.605356693267822\n",
      "EPOCH-3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████| 30/30 [00:01<00:00, 20.18it/s, acc1=0.929, acc5=5.22, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.605041512522978\n",
      "Top-1 Train Accuracy-0.9929411764705882\n",
      "Top-5 Train Accuracy-5.084705882352941\n",
      "Validation Accuracy-0.9292763153711955\n",
      "Validation Loss-4.605413405100505\n",
      "EPOCH-4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 30/30 [00:01<00:00, 16.59it/s, acc1=0.929, acc5=5.28, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.6050406593771545\n",
      "Top-1 Train Accuracy-0.9811764705882353\n",
      "Top-5 Train Accuracy-4.896470588235294\n",
      "Validation Accuracy-0.9292763153711955\n",
      "Validation Loss-4.605234829584758\n",
      "Step-2 Training with both activations and weights binarized for 5 epochs\n",
      "EPOCH-0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 30/30 [00:02<00:00, 11.99it/s, acc1=1.19, acc5=5.23, loss=4.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.607694896832634\n",
      "Top-1 Train Accuracy-0.9152941176470588\n",
      "Top-5 Train Accuracy-5.049411764705883\n",
      "Validation Accuracy-1.194490130742391\n",
      "Validation Loss-4.60526213645935\n",
      "EPOCH-1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████| 30/30 [00:02<00:00, 10.01it/s, acc1=0.82, acc5=4.85, loss=4.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.605429610667509\n",
      "Top-1 Train Accuracy-0.9623529411764706\n",
      "Top-5 Train Accuracy-5.023529411764706\n",
      "Validation Accuracy-0.8203125\n",
      "Validation Loss-4.605466397603353\n",
      "EPOCH-2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████| 30/30 [00:02<00:00, 11.81it/s, acc1=0.872, acc5=5.01, loss=4.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.605048231326832\n",
      "Top-1 Train Accuracy-0.9435294117647058\n",
      "Top-5 Train Accuracy-4.903529411764706\n",
      "Validation Accuracy-0.8723958333333334\n",
      "Validation Loss-4.6055182933807375\n",
      "EPOCH-3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████| 30/30 [00:02<00:00, 11.11it/s, acc1=0.924, acc5=4.87, loss=4.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.605046349828384\n",
      "Top-1 Train Accuracy-1.0070588235294118\n",
      "Top-5 Train Accuracy-5.0329411764705885\n",
      "Validation Accuracy-0.9244791666666666\n",
      "Validation Loss-4.605253887176514\n",
      "EPOCH-4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████| 30/30 [00:02<00:00, 11.62it/s, acc1=0.955, acc5=4.94, loss=4.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss-4.605047231741512\n",
      "Top-1 Train Accuracy-1.011764705882353\n",
      "Top-5 Train Accuracy-5.181176470588236\n",
      "Validation Accuracy-0.9553179820378621\n",
      "Validation Loss-4.605306879679362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fin = a.compress_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e44a4",
   "metadata": {},
   "source": [
    "# Evaluate binarized model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d645c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = torch.load(\"./save_path_mbnet_cifar100_0fp/step2/c100-model_best.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk[\"best_top1_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f9a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
