{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0861404",
   "metadata": {},
   "source": [
    "# BNN-BN\n",
    "This notebook demonstrates the implementation of the BNN-BN Paper\n",
    "# Steps to binarize the model\n",
    "- Load Dataset and DataLoader\n",
    "- Create the teacher model to be binarized\n",
    "- Load the configuration YAML file\n",
    "- create `BNNBN object` and pass the student model, dataloader, configuration\n",
    "- Binarize the model by using `compress_model` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba25adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../../../\")\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from trailmet.models import ModelsFactory\n",
    "from trailmet.datasets.classification import DatasetFactory\n",
    "from trailmet.algorithms.binarize.utils import *\n",
    "from trailmet.algorithms.binarize.BNNBN import BNNBN\n",
    "from trailmet.models.models_bnnbn.Qa_reactnet_18_bn import birealnet18 as Qa_reactnet_18_bn\n",
    "from trailmet.models.models_bnnbn.Qa_reactnet_18_none import birealnet18 as Qa_reactnet_18_none\n",
    "from trailmet.models.models_bnnbn.Qa_reactnet_18_bf import birealnet18 as Qa_reactnet_18_bf\n",
    "\n",
    "from trailmet.models.models_bnnbn.Qaw_reactnet_18_bn import birealnet18 as Qaw_reactnet_18_bn\n",
    "from trailmet.models.models_bnnbn.Qaw_reactnet_18_none import birealnet18 as Qaw_reactnet_18_none\n",
    "from trailmet.models.models_bnnbn.Qaw_reactnet_18_bf import birealnet18 as Qaw_reactnet_18_bf\n",
    "\n",
    "#reactnet-A\n",
    "from trailmet.models.models_bnnbn.Qa_reactnet_A_bn import reactnet as Qa_reactnet_A_bn\n",
    "from trailmet.models.models_bnnbn.Qa_reactnet_A_none import reactnet as Qa_reactnet_A_none\n",
    "from trailmet.models.models_bnnbn.Qa_reactnet_A_bf import reactnet as Qa_reactnet_A_bf\n",
    "\n",
    "from trailmet.models.models_bnnbn.Qaw_reactnet_A_bn import reactnet as Qaw_reactnet_A_bn\n",
    "from trailmet.models.models_bnnbn.Qaw_reactnet_A_none import reactnet as Qaw_reactnet_A_none\n",
    "from trailmet.models.models_bnnbn.Qaw_reactnet_A_bf import reactnet as Qaw_reactnet_A_bf\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957b031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f7710d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATASET': 'c100',\n",
       " 'arch': 'reactnet-A',\n",
       " 'binary_w': True,\n",
       " 'bn_type': 'none',\n",
       " 'batch_size': 256,\n",
       " 'workers': 4,\n",
       " 'valid_size': 0.1,\n",
       " 'num_train': 0,\n",
       " 'num_classes': 100,\n",
       " 'insize': 32,\n",
       " 'loss_type': 'ce',\n",
       " 'teacher': 'resnet34',\n",
       " 'teacher_weight': '',\n",
       " 'label_smooth': 0.1,\n",
       " 'pretrained': '',\n",
       " 'resume': False,\n",
       " 'save': './saved_weights',\n",
       " 'epoch': 5,\n",
       " 'agc': True,\n",
       " 'clip_value': 0.04,\n",
       " 'weight_decay': 0,\n",
       " 'learning_rate': 0.001}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = './'\n",
    "import os\n",
    "with open(os.path.join(root_dir,\"bnnbn_cifar100.yaml\"),'r') as stream:\n",
    "    kwargs = yaml.safe_load(stream)\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd0e401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "    \n",
    "set_seed(1024)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad2438",
   "metadata": {},
   "source": [
    "# Defining the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32aa3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Model = reactnet-A\n",
      "* Binarize both activation and weights\n",
      "* without BN\n"
     ]
    }
   ],
   "source": [
    "if kwargs['arch'] == 'reactnet-18':\n",
    "    print('* Model = ReActNet-18')\n",
    "    if kwargs['binary_w']:\n",
    "        print('* Binarize both activation and weights')\n",
    "        if kwargs['bn_type'] == 'bn':\n",
    "            print('* with BN')\n",
    "            model = Qaw_reactnet_18_bn(num_classes=kwargs['num_classes'])\n",
    "        elif kwargs['bn_type'] == 'none':\n",
    "            print('* without BN')\n",
    "            model = Qaw_reactnet_18_none(num_classes=kwargs['num_classes'])\n",
    "        elif kwargs['bn_type'] == 'bf':\n",
    "            print('* BN-Free')\n",
    "            model = Qaw_reactnet_18_bf(num_classes=kwargs['num_classes'])\n",
    "\n",
    "    else:\n",
    "        print('* Binarize only activation')\n",
    "        if kwargs['bn_type'] == 'bn':\n",
    "            print('* with BN')\n",
    "            model = Qa_reactnet_18_bn(num_classes=kwargs['num_classes'])\n",
    "        elif kwargs['bn_type'] == 'none':\n",
    "            print('* without BN')\n",
    "            model = Qa_reactnet_18_none(num_classes=kwargs['num_classes'])\n",
    "        elif kwargs['bn_type'] == 'bf':\n",
    "            print('* BN-Free')\n",
    "            model = Qa_reactnet_18_bf(num_classes=kwargs['num_classes'])\n",
    "\n",
    "\n",
    "elif kwargs['arch'] == 'reactnet-A':\n",
    "    print('* Model = reactnet-A')\n",
    "    if kwargs['binary_w']:\n",
    "        print('* Binarize both activation and weights')\n",
    "        if kwargs['bn_type'] == 'bn':\n",
    "            print('* with BN')\n",
    "            model = Qaw_reactnet_A_bn(num_classes=kwargs['num_classes'])\n",
    "        elif kwargs['bn_type'] == 'none':\n",
    "            print('* without BN')\n",
    "            model = Qaw_reactnet_A_none(num_classes=kwargs['num_classes'])\n",
    "        elif kwargs['bn_type'] == 'bf':\n",
    "            print('* BN-Free')\n",
    "            model = Qaw_reactnet_A_bf(num_classes=kwargs['num_classes'])\n",
    "\n",
    "    else:\n",
    "        print('* Binarize only activation')\n",
    "        if kwargs['bn_type'] == 'bn':\n",
    "            print('* with BN')\n",
    "            model = Qa_reactnet_A_bn(num_classes=kwargs['num_classes'])\n",
    "        elif kwargs['bn_type'] == 'none':\n",
    "            print('* without BN')\n",
    "            model = Qa_reactnet_A_none(num_classes=kwargs['num_classes'])\n",
    "        elif kwargs['bn_type'] == 'bf':\n",
    "            print('* BN-Free')\n",
    "            model = Qa_reactnet_A_bf(num_classes=kwargs['num_classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8d708",
   "metadata": {},
   "source": [
    "# Augmentation, Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf869e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Augmentation\n",
    "crop_scale = 0.08\n",
    "lighting_param = 0.1\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(crop_scale, 1.0)),\n",
    "    Lighting(lighting_param),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "        transforms.Resize(36),\n",
    "        transforms.CenterCrop(32),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "test_transform = valid_transform\n",
    "\n",
    "input_transforms = {\n",
    "    'train': train_transform, \n",
    "    'val': valid_transform, \n",
    "    'test': test_transform}\n",
    "\n",
    "target_transforms = {\n",
    "    'train': None, \n",
    "    'val': None, \n",
    "    'test': None}\n",
    "\n",
    "# Create Dataset\n",
    "cifar100_dataset = DatasetFactory.create_dataset(name = 'CIFAR100', \n",
    "                                        root = root_dir,\n",
    "                                        split_types = ['train', 'val', 'test'],\n",
    "                                        val_fraction = 0.15,\n",
    "                                        transform = input_transforms,\n",
    "                                        target_transform = target_transforms\n",
    "                                        )\n",
    "# Define DataLoaders\n",
    "train_loader100 = torch.utils.data.DataLoader(\n",
    "        cifar100_dataset['train'], batch_size=kwargs['batch_size'], \n",
    "        sampler=cifar100_dataset['train_sampler'],\n",
    "        num_workers=kwargs['workers']\n",
    "    )\n",
    "val_loader100 = torch.utils.data.DataLoader(\n",
    "        cifar100_dataset['val'], batch_size=kwargs['batch_size'], \n",
    "        sampler=cifar100_dataset['val_sampler'],\n",
    "        num_workers=kwargs['workers']\n",
    "    )\n",
    "test_loader100 = torch.utils.data.DataLoader(\n",
    "        cifar100_dataset['test'], batch_size=kwargs['batch_size'], \n",
    "        sampler=cifar100_dataset['test_sampler'],\n",
    "        num_workers=kwargs['workers']\n",
    "    )\n",
    "\n",
    "dataloaders = {\n",
    "        'train': train_loader100, 'val': val_loader100, \"test\": test_loader100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a345d",
   "metadata": {},
   "source": [
    "# ReActNet Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f639059",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = BNNBN(model, dataloaders, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87899d6f",
   "metadata": {},
   "source": [
    "# Binarizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758d68c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reactnet(\n",
      "  (feature): ModuleList(\n",
      "    (0): firstconv3x3(\n",
      "      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=32)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw_down1): HardBinaryConv()\n",
      "      (binary_pw_down2): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=64)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "      (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=64)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw_down1): HardBinaryConv()\n",
      "      (binary_pw_down2): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=128)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "      (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=128)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=128)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=128)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw_down1): HardBinaryConv()\n",
      "      (binary_pw_down2): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=256)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "      (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=256)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=256)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=256)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw_down1): HardBinaryConv()\n",
      "      (binary_pw_down2): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=512)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "      (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=512)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=512)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=512)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=512)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=512)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=512)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=512)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=512)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=512)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=512)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=512)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw_down1): HardBinaryConv()\n",
      "      (binary_pw_down2): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=1024)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "      (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (move11): LearnableBias()\n",
      "      (binary_3x3): HardBinaryConv()\n",
      "      (move12): LearnableBias()\n",
      "      (prelu1): PReLU(num_parameters=1024)\n",
      "      (move13): LearnableBias()\n",
      "      (move21): LearnableBias()\n",
      "      (binary_pw): HardBinaryConv()\n",
      "      (move22): LearnableBias()\n",
      "      (prelu2): PReLU(num_parameters=1024)\n",
      "      (move23): LearnableBias()\n",
      "      (binary_activation): BinaryActivation()\n",
      "    )\n",
      "  )\n",
      "  (pool1): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=1024, out_features=100, bias=True)\n",
      ")\n",
      "learning_rate: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/167]\tTime 16.909 (16.909)\tData  1.319 ( 1.319)\tLoss 1.9196e+01 (1.9196e+01)\tAcc@1   0.39 (  0.39)\tAcc@5   6.25 (  6.25)\n",
      "Epoch: [0][ 50/167]\tTime  0.236 ( 0.529)\tData  0.017 ( 0.046)\tLoss 4.7309e+00 (5.2994e+00)\tAcc@1   2.73 (  1.05)\tAcc@5   6.25 (  5.21)\n",
      "Epoch: [0][100/167]\tTime  0.316 ( 0.359)\tData  0.003 ( 0.029)\tLoss 4.6184e+00 (5.0228e+00)\tAcc@1   2.73 (  1.45)\tAcc@5  12.89 (  6.61)\n",
      "Epoch: [0][150/167]\tTime  0.187 ( 0.311)\tData  0.015 ( 0.024)\tLoss 4.4383e+00 (4.8585e+00)\tAcc@1   1.56 (  1.95)\tAcc@5  14.84 (  8.53)\n",
      "Test: [ 0/30]\tTime  0.965 ( 0.965)\tLoss 4.5577e+00 (4.5577e+00)\tAcc@1   3.91 (  3.91)\tAcc@5  12.50 ( 12.50)\n",
      " * acc@1 4.200 acc@5 15.293\n",
      "learning_rate: 0.0006\n",
      "Epoch: [1][  0/167]\tTime  1.332 ( 1.332)\tData  1.076 ( 1.076)\tLoss 4.4081e+00 (4.4081e+00)\tAcc@1   5.08 (  5.08)\tAcc@5  15.62 ( 15.62)\n",
      "Epoch: [1][ 50/167]\tTime  0.279 ( 0.214)\tData  0.026 ( 0.038)\tLoss 4.2289e+00 (4.3032e+00)\tAcc@1   6.25 (  4.90)\tAcc@5  22.27 ( 18.16)\n",
      "Epoch: [1][100/167]\tTime  0.101 ( 0.189)\tData  0.004 ( 0.025)\tLoss 4.2018e+00 (4.2391e+00)\tAcc@1   5.86 (  5.65)\tAcc@5  21.88 ( 20.06)\n",
      "Epoch: [1][150/167]\tTime  0.215 ( 0.183)\tData  0.004 ( 0.021)\tLoss 4.0421e+00 (4.2062e+00)\tAcc@1  10.94 (  6.02)\tAcc@5  26.95 ( 20.95)\n",
      "Test: [ 0/30]\tTime  0.841 ( 0.841)\tLoss 3.9787e+00 (3.9787e+00)\tAcc@1   7.42 (  7.42)\tAcc@5  24.61 ( 24.61)\n",
      " * acc@1 8.320 acc@5 26.160\n",
      "learning_rate: 0.0004\n",
      "Epoch: [2][  0/167]\tTime  1.749 ( 1.749)\tData  1.442 ( 1.442)\tLoss 4.1161e+00 (4.1161e+00)\tAcc@1   6.25 (  6.25)\tAcc@5  19.53 ( 19.53)\n",
      "Epoch: [2][ 50/167]\tTime  0.131 ( 0.255)\tData  0.005 ( 0.048)\tLoss 3.9153e+00 (4.0196e+00)\tAcc@1  10.55 (  8.14)\tAcc@5  28.52 ( 26.48)\n",
      "Epoch: [2][100/167]\tTime  0.189 ( 0.225)\tData  0.007 ( 0.031)\tLoss 3.8879e+00 (3.9901e+00)\tAcc@1  10.94 (  8.86)\tAcc@5  28.12 ( 27.17)\n",
      "Epoch: [2][150/167]\tTime  0.208 ( 0.211)\tData  0.013 ( 0.024)\tLoss 3.8434e+00 (3.9707e+00)\tAcc@1  11.72 (  9.13)\tAcc@5  28.91 ( 27.81)\n",
      "Test: [ 0/30]\tTime  0.889 ( 0.889)\tLoss 3.9764e+00 (3.9764e+00)\tAcc@1   9.77 (  9.77)\tAcc@5  23.44 ( 23.44)\n",
      " * acc@1 10.680 acc@5 30.613\n",
      "learning_rate: 0.00019999999999999996\n",
      "Epoch: [3][  0/167]\tTime  1.051 ( 1.051)\tData  0.921 ( 0.921)\tLoss 3.9478e+00 (3.9478e+00)\tAcc@1  10.94 ( 10.94)\tAcc@5  29.30 ( 29.30)\n",
      "Epoch: [3][ 50/167]\tTime  0.099 ( 0.160)\tData  0.004 ( 0.028)\tLoss 3.6596e+00 (3.8286e+00)\tAcc@1  14.84 ( 11.27)\tAcc@5  37.11 ( 32.34)\n",
      "Epoch: [3][100/167]\tTime  0.252 ( 0.174)\tData  0.003 ( 0.018)\tLoss 3.9405e+00 (3.8137e+00)\tAcc@1   8.98 ( 11.39)\tAcc@5  26.95 ( 32.75)\n",
      "Epoch: [3][150/167]\tTime  0.196 ( 0.172)\tData  0.003 ( 0.016)\tLoss 3.7249e+00 (3.7997e+00)\tAcc@1  12.89 ( 11.72)\tAcc@5  36.33 ( 33.28)\n",
      "Test: [ 0/30]\tTime  1.241 ( 1.241)\tLoss 3.5579e+00 (3.5579e+00)\tAcc@1  15.62 ( 15.62)\tAcc@5  39.45 ( 39.45)\n",
      " * acc@1 14.187 acc@5 37.587\n",
      "learning_rate: 0.0\n",
      "Epoch: [4][  0/167]\tTime  1.540 ( 1.540)\tData  1.397 ( 1.397)\tLoss 3.7118e+00 (3.7118e+00)\tAcc@1  12.11 ( 12.11)\tAcc@5  36.33 ( 36.33)\n",
      "Epoch: [4][ 50/167]\tTime  0.142 ( 0.246)\tData  0.004 ( 0.042)\tLoss 3.6616e+00 (3.7138e+00)\tAcc@1  14.06 ( 12.85)\tAcc@5  35.55 ( 35.67)\n",
      "Epoch: [4][100/167]\tTime  0.134 ( 0.217)\tData  0.008 ( 0.026)\tLoss 3.8587e+00 (3.7303e+00)\tAcc@1  10.94 ( 12.69)\tAcc@5  31.25 ( 35.28)\n",
      "Epoch: [4][150/167]\tTime  0.120 ( 0.203)\tData  0.006 ( 0.020)\tLoss 3.7817e+00 (3.7284e+00)\tAcc@1  10.55 ( 12.68)\tAcc@5  35.16 ( 35.21)\n",
      "Test: [ 0/30]\tTime  0.926 ( 0.926)\tLoss 3.7790e+00 (3.7790e+00)\tAcc@1  12.11 ( 12.11)\tAcc@5  35.16 ( 35.16)\n",
      " * acc@1 14.160 acc@5 37.640\n",
      "total training time = 0.0685397023624844 hours\n",
      "* best acc = 14.186666488647461\n"
     ]
    }
   ],
   "source": [
    "fin = a.compress_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b9c82",
   "metadata": {},
   "source": [
    "# Evaluate binarized model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f8ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk=torch.load('./saved_weights/model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54349854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.1867, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk['best_top1_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31aca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
