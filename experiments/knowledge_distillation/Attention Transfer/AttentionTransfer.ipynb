{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XDxrKjjSxP9"
      },
      "source": [
        "# Attention Transfer\n",
        "\n",
        "This notebook demonstrates the implementation of this paper [Paying More Attention to Attention](https://arxiv.org/abs/1612.03928)\n",
        "\n",
        "## Steps to transfer from a teacher to student model\n",
        "\n",
        "- Load dataset and create dataloaders\n",
        "- Create teacher and student models and load pretrained weights of teacher model\n",
        "- Load the configuration YAML file\n",
        "- Create `AttentionTransfer object` and pass the dataloaders, teacher model, student model and configuration\n",
        "- Transfer the knowledge to student model by using `compress_model` method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QisGHn2_TDTO",
        "outputId": "dad40daf-7696-43e8-dcde-9e76ecf1fb8e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/trailmet/experiments/knowlege_distillation/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smqH26w3TZXc",
        "outputId": "08a2556c-4163-4ed6-df34-7e7284a33a2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/trailmet/experiments/knowlege_distillation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CP9FUD9yVTn3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../../\")\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import yaml\n",
        "\n",
        "from trailmet.algorithms.distill.attention_transfer import AttentionTransfer\n",
        "from trailmet.datasets.classification import DatasetFactory\n",
        "from trailmet.models.resnet import get_resnet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC124keNVTn6"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_mHEwwycVTn8"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z786Cf7ASxQG"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0EwK_RVoVTn8"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Pad(4, padding_mode='reflect'),\n",
        "                    transforms.RandomHorizontalFlip(p=0.5),\n",
        "                    transforms.RandomCrop(32),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                ]\n",
        "            )\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                ]\n",
        "            )\n",
        "\n",
        "transforms1 = {\n",
        "    'train': transform_train, \n",
        "    'val': transform_test, \n",
        "    'test': transform_test}\n",
        "\n",
        "target_transforms = {\n",
        "    'train': None, \n",
        "    'val': None, \n",
        "    'test': None}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6OL6wyjSxQJ"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHFlUHnSgRTD",
        "outputId": "489a6485-5c60-443f-e676-5b626014d365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar_dataset = DatasetFactory.create_dataset(name = 'CIFAR10', \n",
        "                                        root = \"./data\",\n",
        "                                        split_types = ['train', 'val', 'test'],\n",
        "                                        val_fraction = 0.1,\n",
        "                                        transform = transforms1,\n",
        "                                        target_transform = target_transforms,\n",
        "                                        random_seed=42\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlwvRRCxSxQN"
      },
      "source": [
        "### Define data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PRVfJ1rig3YY"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['train_dataset'], batch_size=128, \n",
        "        sampler=cifar_dataset['train_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['val_dataset'], batch_size=128, \n",
        "        sampler=cifar_dataset['val_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['test_dataset'], batch_size=128, \n",
        "        sampler=cifar_dataset['test_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "dataloaders = {'train':train_loader, 'val':val_loader, 'test':test_loader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frJVv5qoVTn_"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQOrdm6dSxQR"
      },
      "source": [
        "### Create the teacher and student models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XifOZKPAVToB",
        "outputId": "32a39b63-a43a-427b-b43a-64ee37927638"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (activ): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "teacher_model = get_resnet_model('resnet50', 100, 32, False)\n",
        "student_model = get_resnet_model('resnet18', 100, 32, False)\n",
        "\n",
        "teacher_model.to(device)\n",
        "student_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfBWquAjSxQS"
      },
      "source": [
        "### Load Pretrained Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-liOye7jOgP",
        "outputId": "34ad1852-d0a4-4dca-8d05-20c97ce05912"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "weights = torch.load(\"./resnet50_cifar100_pretrained.pth\")['state_dict']\n",
        "teacher_model.load_state_dict(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qxep2srSxQT"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azW_QdvFSxQT"
      },
      "source": [
        "### Load configurations for training the student model\n",
        "\n",
        "The configuration should contain distillation arguments including the training parameters such as total epochs, learning rates, milestones, etc. as well as the names of layers involved in Attention Transfer\n",
        "\n",
        "__Note:__ Running on 5 epochs for demonstration purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOcnc3fNSxQU",
        "outputId": "039af5ea-6579-4a6b-c147-772a16b3e365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DISTILL_ARGS': {'BETA': 1000,\n",
              "  'EPOCHS': 5,\n",
              "  'LR': 0.1,\n",
              "  'WEIGHT_DECAY': 0.0005,\n",
              "  'TEACHER_LAYER_NAMES': ['layer1', 'layer2', 'layer3', 'layer4'],\n",
              "  'STUDENT_LAYER_NAMES': ['layer1', 'layer2', 'layer3', 'layer4'],\n",
              "  'VERBOSE': True},\n",
              " 'log_dir': 'at_resnet50-resnet18',\n",
              " 'cuda_id': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "with open(\"./resnet50-resnet18.yaml\", 'r') as stream:\n",
        "    data_loaded = yaml.safe_load(stream)\n",
        "data_loaded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awBggHtxSxQU"
      },
      "source": [
        "### Training student model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1f1tmxodVToB"
      },
      "outputs": [],
      "source": [
        "distillation_box = AttentionTransfer(teacher_model, student_model, dataloaders, **data_loaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQWD6lfzVToC",
        "outputId": "d122e977-513f-425f-d280-1b27c93b91b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====TRAINING STUDENT NETWORK=====\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [01:10<00:00,  5.02it/s, loss=18]\n",
            "100%|██████████| 40/40 [00:04<00:00,  8.14it/s, acc=0.279, loss=6.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving checkpoint**\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [01:07<00:00,  5.23it/s, loss=6.23]\n",
            "100%|██████████| 40/40 [00:03<00:00, 12.82it/s, acc=0.296, loss=6.06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving checkpoint**\n",
            "Epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [01:03<00:00,  5.51it/s, loss=5.61]\n",
            "100%|██████████| 40/40 [00:02<00:00, 14.27it/s, acc=0.439, loss=5.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving checkpoint**\n",
            "Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [01:03<00:00,  5.54it/s, loss=5.09]\n",
            "100%|██████████| 40/40 [00:02<00:00, 16.80it/s, acc=0.54, loss=5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving checkpoint**\n",
            "Epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [01:03<00:00,  5.52it/s, loss=4.6]\n",
            "100%|██████████| 40/40 [00:02<00:00, 16.99it/s, acc=0.587, loss=4.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Saving checkpoint**\n"
          ]
        }
      ],
      "source": [
        "distillation_box.compress_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAXUfcmXSxQW"
      },
      "source": [
        "# Evaluate student model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-5DKHX-ocQz",
        "outputId": "66a4b3e5-52d5-4946-a654-04286fe80db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:03<00:00, 22.73it/s]\n"
          ]
        }
      ],
      "source": [
        "student_model.load_state_dict(torch.load(f\"./checkpoints/{data_loaded['log_dir']}.pth\")['state_dict'])\n",
        "\n",
        "preds = []\n",
        "valid_labels = []\n",
        "student_model.eval()\n",
        "# Run the best model on test set\n",
        "for step, (images, labels) in tqdm(enumerate(test_loader), total = len(test_loader)):\n",
        "\n",
        "    images = images.to(device, dtype=torch.float)\n",
        "    labels = labels.to(device)\n",
        "    batch_size = labels.size(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_preds = student_model(images)\n",
        "        \n",
        "    preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
        "    valid_labels.append(labels.to('cpu').numpy())\n",
        "\n",
        "predictions = np.concatenate(preds)\n",
        "valid_labels = np.concatenate(valid_labels)\n",
        "\n",
        "# Get the score\n",
        "score = accuracy_score(valid_labels, predictions.argmax(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J8ItJcySxQY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "c20c3092c0956f53c057234954b0e6e2beb63c056f97db512353abbe859d97b3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}