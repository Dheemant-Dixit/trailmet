{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vUfKaniYlfRG"
      },
      "source": [
        "# Factor Transfer\n",
        "\n",
        "This notebook demonstrates the implementation of this paper [Paraphrasing Complex Network: Network Compression via Factor Transfer](https://arxiv.org/abs/1802.04977)\n",
        "\n",
        "## Steps to transfer from a teacher to student model\n",
        "\n",
        "- Load dataset and create dataloaders\n",
        "- Create teacher and student models and load pretrained weights of teacher model\n",
        "- Load the configuration YAML file\n",
        "- Create `FactorTransfer` object and pass the dataloaders, teacher model, student model and configuration\n",
        "- Transfer the knowledge to student model by using `compress_model` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CP9FUD9yVTn3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../../../\")\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import yaml\n",
        "\n",
        "from trailmet.algorithms.distill.factor_transfer import FactorTransfer\n",
        "from trailmet.datasets.classification import DatasetFactory\n",
        "from trailmet.models import ModelsFactory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pC124keNVTn6"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rv4xfg2RmYVE"
      },
      "source": [
        "### Define data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_mHEwwycVTn8"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uYd1z5qoohRk"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0EwK_RVoVTn8"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Pad(4, padding_mode='reflect'),\n",
        "                    transforms.RandomHorizontalFlip(p=0.5),\n",
        "                    transforms.RandomCrop(32),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                ]\n",
        "            )\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                ]\n",
        "            )\n",
        "\n",
        "transforms1 = {\n",
        "    'train': transform_train, \n",
        "    'val': transform_test, \n",
        "    'test': transform_test}\n",
        "\n",
        "target_transforms = {\n",
        "    'train': None, \n",
        "    'val': None, \n",
        "    'test': None}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ650zARosBu"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovApHJb0lVUJ",
        "outputId": "7cbfb626-1ff8-49c5-abb6-7ed30c9907e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar_dataset = DatasetFactory.create_dataset(name = 'CIFAR10', \n",
        "                                        root = \"./data\",\n",
        "                                        split_types = ['train', 'val', 'test'],\n",
        "                                        val_fraction = 0.1,\n",
        "                                        transform = transforms1,\n",
        "                                        target_transform = target_transforms,\n",
        "                                        random_seed=42\n",
        "                                        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKEAdOorm_iM"
      },
      "source": [
        "### Define data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s0saqMh6lVUJ"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['train'], batch_size=128, \n",
        "        sampler=cifar_dataset['train_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['val'], batch_size=128, \n",
        "        sampler=cifar_dataset['val_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['test'], batch_size=128, \n",
        "        sampler=cifar_dataset['test_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "dataloaders = {'train':train_loader, 'val':val_loader, 'test':test_loader}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load configurations for training the student model\n",
        "\n",
        "The configuration should contain distillation arguments including the training parameters such as total epochs, learning rates, milestones, etc. as well as the name of layer involved in Factor Transfer\n",
        "\n",
        "__Note:__ Running on 5 epochs for demonstration purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DISTILL_ARGS': {'BETA': 500,\n",
              "  'EPOCHS': 5,\n",
              "  'LR': 0.1,\n",
              "  'WEIGHT_DECAY': 0.0005,\n",
              "  'MILESTONES': [82, 123],\n",
              "  'GAMMA': 0.1,\n",
              "  'IN_PLANES': 512,\n",
              "  'RATE': 2,\n",
              "  'TEACHER_LAYER_NAME': 'layer4',\n",
              "  'STUDENT_LAYER_NAME': 'layer4',\n",
              "  'VERBOSE': True},\n",
              " 'PARAPHRASER': {'IN_PLANES': 2048,\n",
              "  'RATE': 0.5,\n",
              "  'EPOCHS': 1,\n",
              "  'LR': 0.1,\n",
              "  'WEIGHT_DECAY': 0.0005},\n",
              " 'log_dir': 'ft_resnet50-resnet18',\n",
              " 'DEVICE': 'cuda',\n",
              " 'insize': 32,\n",
              " 'wandb': True}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"./resnet50-resnet18.yaml\", 'r') as stream:\n",
        "    data_loaded = yaml.safe_load(stream)\n",
        "data_loaded"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "frJVv5qoVTn_"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A4BHgr_TnXsV"
      },
      "source": [
        "### Create the teacher and student models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XifOZKPAVToB",
        "outputId": "8f236be5-a971-4220-c7da-99ab9a5c8740"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (activ): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "teacher_model = ModelsFactory.create_model(name='resnet50', num_classes=100, version=\"original\", pretrained=False, **data_loaded)\n",
        "student_model = ModelsFactory.create_model(name='resnet18', num_classes=100, version=\"original\", pretrained=False, **data_loaded)\n",
        "\n",
        "teacher_model.to(device)\n",
        "student_model.to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F7N9PQKVnvrD"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1f1tmxodVToB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manimesh-007\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.15.4 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/workspace/animesh_trailmet/experiments/distillation/Factor Transfer/wandb/run-20230625_205811-vmpwn08j</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/animesh-007/Trailmet%20Factor_Transfer/runs/vmpwn08j' target=\"_blank\">CIFAR10_5_0.1_Jun-25_20:58:09</a></strong> to <a href='https://wandb.ai/animesh-007/Trailmet%20Factor_Transfer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/animesh-007/Trailmet%20Factor_Transfer' target=\"_blank\">https://wandb.ai/animesh-007/Trailmet%20Factor_Transfer</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/animesh-007/Trailmet%20Factor_Transfer/runs/vmpwn08j' target=\"_blank\">https://wandb.ai/animesh-007/Trailmet%20Factor_Transfer/runs/vmpwn08j</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "distillation_box = FactorTransfer(teacher_model, student_model, dataloaders, **data_loaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQWD6lfzVToC",
        "outputId": "3adc8115-b4b1-4970-9382-eb9e95b50859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====> TRAINING PARAPHRASER <=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training paraphraser Epoch [0] (352 / 352 Steps) (batch time=0.03953s) (data time=0.00195s) (loss=nan): 100%|| 352/352 [00:17<00:00, 20.62it/s]              \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====> TRAINING STUDENT NETWORK <=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training student network Epoch [0] (352 / 352 Steps) (batch time=0.03301s) (data time=0.00273s) (loss=nan): 100%|| 352/352 [00:13<00:00, 25.34it/s]\n",
            "Validating student network Epoch [0] (40 / 40 Steps) (batch time=0.01934s) (loss=nan) (top1=50.00000) (top5=75.00000): 100%|| 40/40 [00:01<00:00, 32.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * acc@1 43.060 acc@5 90.160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training student network Epoch [1] (352 / 352 Steps) (batch time=0.03138s) (data time=0.00216s) (loss=nan): 100%|| 352/352 [00:13<00:00, 26.63it/s]\n",
            "Validating student network Epoch [1] (40 / 40 Steps) (batch time=0.02281s) (loss=nan) (top1=75.00000) (top5=100.00000): 100%|| 40/40 [00:01<00:00, 31.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * acc@1 53.040 acc@5 94.400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training student network Epoch [2] (352 / 352 Steps) (batch time=0.03378s) (data time=0.00341s) (loss=nan): 100%|| 352/352 [00:13<00:00, 26.40it/s]\n",
            "Validating student network Epoch [2] (40 / 40 Steps) (batch time=0.01816s) (loss=nan) (top1=75.00000) (top5=100.00000): 100%|| 40/40 [00:01<00:00, 34.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * acc@1 63.380 acc@5 96.460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training student network Epoch [3] (352 / 352 Steps) (batch time=0.03521s) (data time=0.00269s) (loss=nan): 100%|| 352/352 [00:13<00:00, 26.68it/s]\n",
            "Validating student network Epoch [3] (40 / 40 Steps) (batch time=0.01729s) (loss=nan) (top1=75.00000) (top5=100.00000): 100%|| 40/40 [00:01<00:00, 32.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * acc@1 65.140 acc@5 97.480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training student network Epoch [4] (352 / 352 Steps) (batch time=0.03298s) (data time=0.00200s) (loss=nan): 100%|| 352/352 [00:13<00:00, 26.96it/s]\n",
            "Validating student network Epoch [4] (40 / 40 Steps) (batch time=0.01989s) (loss=nan) (top1=75.00000) (top5=100.00000): 100%|| 40/40 [00:01<00:00, 30.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * acc@1 66.780 acc@5 96.980\n"
          ]
        }
      ],
      "source": [
        "distillation_box.compress_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "c20c3092c0956f53c057234954b0e6e2beb63c056f97db512353abbe859d97b3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
