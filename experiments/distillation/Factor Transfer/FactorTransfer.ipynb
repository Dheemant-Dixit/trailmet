{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUfKaniYlfRG"
      },
      "source": [
        "# Factor Transfer\n",
        "\n",
        "This notebook demonstrates the implementation of this paper [Paraphrasing Complex Network: Network Compression via Factor Transfer](https://arxiv.org/abs/1802.04977)\n",
        "\n",
        "## Steps to transfer from a teacher to student model\n",
        "\n",
        "- Load dataset and create dataloaders\n",
        "- Create teacher and student models and load pretrained weights of teacher model\n",
        "- Load the configuration YAML file\n",
        "- Create `FactorTransfer` object and pass the dataloaders, teacher model, student model and configuration\n",
        "- Transfer the knowledge to student model by using `compress_model` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CP9FUD9yVTn3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../../\")\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import yaml\n",
        "\n",
        "from trailmet.algorithms.distill.factor_transfer import FactorTransfer\n",
        "from trailmet.datasets.classification import DatasetFactory\n",
        "from trailmet.models.resnet import get_resnet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC124keNVTn6"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv4xfg2RmYVE"
      },
      "source": [
        "### Define data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_mHEwwycVTn8"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYd1z5qoohRk"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0EwK_RVoVTn8"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Pad(4, padding_mode='reflect'),\n",
        "                    transforms.RandomHorizontalFlip(p=0.5),\n",
        "                    transforms.RandomCrop(32),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                ]\n",
        "            )\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                ]\n",
        "            )\n",
        "\n",
        "transforms1 = {\n",
        "    'train': transform_train, \n",
        "    'val': transform_test, \n",
        "    'test': transform_test}\n",
        "\n",
        "target_transforms = {\n",
        "    'train': None, \n",
        "    'val': None, \n",
        "    'test': None}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ650zARosBu"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovApHJb0lVUJ",
        "outputId": "7cbfb626-1ff8-49c5-abb6-7ed30c9907e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar_dataset = DatasetFactory.create_dataset(name = 'CIFAR10', \n",
        "                                        root = \"./data\",\n",
        "                                        split_types = ['train', 'val', 'test'],\n",
        "                                        val_fraction = 0.1,\n",
        "                                        transform = transforms1,\n",
        "                                        target_transform = target_transforms,\n",
        "                                        random_seed=42\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKEAdOorm_iM"
      },
      "source": [
        "### Define data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s0saqMh6lVUJ"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['train_dataset'], batch_size=128, \n",
        "        sampler=cifar_dataset['train_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['val_dataset'], batch_size=128, \n",
        "        sampler=cifar_dataset['val_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['test_dataset'], batch_size=128, \n",
        "        sampler=cifar_dataset['test_sampler'],\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "dataloaders = {'train':train_loader, 'val':val_loader, 'test':test_loader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frJVv5qoVTn_"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4BHgr_TnXsV"
      },
      "source": [
        "### Create the teacher and student models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XifOZKPAVToB",
        "outputId": "8f236be5-a971-4220-c7da-99ab9a5c8740"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (activ): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activ): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "teacher_model = get_resnet_model('resnet50', 100, 32, False)\n",
        "student_model = get_resnet_model('resnet18', 100, 32, False)\n",
        "\n",
        "teacher_model.to(device)\n",
        "student_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEJGQ5bJnsaT"
      },
      "source": [
        "### Load Pretrained Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-liOye7jOgP",
        "outputId": "001a6d1d-094d-45df-c8c0-72529508d25d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = torch.load(\"./resnet50_cifar100_pretrained.pth\")['state_dict']\n",
        "teacher_model.load_state_dict(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7N9PQKVnvrD"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCZL5C8rnznM"
      },
      "source": [
        "### Load configurations for training the student model\n",
        "\n",
        "The configuration should contain distillation arguments including the training parameters such as total epochs, learning rates, milestones, etc. as well as the name of layer involved in Factor Transfer\n",
        "\n",
        "__Note:__ Running on 5 epochs for demonstration purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0sxGqoJpI1j",
        "outputId": "efbed58c-f4f9-4264-f29a-261e783e8692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DISTILL_ARGS': {'BETA': 500,\n",
              "  'EPOCHS': 5,\n",
              "  'LR': 0.1,\n",
              "  'WEIGHT_DECAY': 0.0005,\n",
              "  'IN_PLANES': 512,\n",
              "  'RATE': 2,\n",
              "  'TEACHER_LAYER_NAME': 'layer4',\n",
              "  'STUDENT_LAYER_NAME': 'layer4',\n",
              "  'VERBOSE': True},\n",
              " 'PARAPHRASER': {'IN_PLANES': 2048,\n",
              "  'RATE': 0.5,\n",
              "  'EPOCHS': 1,\n",
              "  'LR': 0.1,\n",
              "  'WEIGHT_DECAY': 0.0005},\n",
              " 'log_dir': 'ft_resnet50-resnet18',\n",
              " 'cuda_id': 0}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"./resnet50-resnet18.yaml\", 'r') as stream:\n",
        "    data_loaded = yaml.safe_load(stream)\n",
        "data_loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1f1tmxodVToB"
      },
      "outputs": [],
      "source": [
        "distillation_box = FactorTransfer(teacher_model, student_model, dataloaders, **data_loaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQWD6lfzVToC",
        "outputId": "3adc8115-b4b1-4970-9382-eb9e95b50859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====TRAINING PARAPHRASER=====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 352/352 [01:50<00:00,  3.17it/s, loss=0.14]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train loss: 0.1395\n",
            "=====TRAINING STUDENT NETWORK=====\n",
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 352/352 [00:47<00:00,  7.38it/s, loss=3.48]\n",
            "100%|██████████| 40/40 [00:03<00:00, 11.08it/s, acc=0.427, loss=2.93]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Saving checkpoint**\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 352/352 [00:46<00:00,  7.53it/s, loss=2.71]\n",
            "100%|██████████| 40/40 [00:03<00:00, 11.90it/s, acc=0.581, loss=2.52]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Saving checkpoint**\n",
            "Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 352/352 [00:48<00:00,  7.28it/s, loss=2.42]\n",
            "100%|██████████| 40/40 [00:03<00:00, 10.73it/s, acc=0.64, loss=2.32]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Saving checkpoint**\n",
            "Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 352/352 [00:46<00:00,  7.53it/s, loss=2.26]\n",
            "100%|██████████| 40/40 [00:03<00:00, 12.04it/s, acc=0.67, loss=2.25]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Saving checkpoint**\n",
            "Epoch: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 352/352 [00:46<00:00,  7.58it/s, loss=2.15]\n",
            "100%|██████████| 40/40 [00:03<00:00, 10.02it/s, acc=0.71, loss=2.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Saving checkpoint**\n"
          ]
        }
      ],
      "source": [
        "distillation_box.compress_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSD-N2DkuHmG"
      },
      "source": [
        "# Evaluate student model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ycR8w5lVUM",
        "outputId": "5ef6aa8a-1bfd-43a8-90fd-39c2dbeb6120"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:03<00:00, 25.07it/s]\n"
          ]
        }
      ],
      "source": [
        "student_model.load_state_dict(torch.load(f\"./checkpoints/{data_loaded['log_dir']}.pth\")['state_dict'])\n",
        "\n",
        "preds = []\n",
        "valid_labels = []\n",
        "student_model.eval()\n",
        "# Run the best model on test set\n",
        "for step, (images, labels) in tqdm(enumerate(test_loader), total = len(test_loader)):\n",
        "\n",
        "    images = images.to(device, dtype=torch.float)\n",
        "    labels = labels.to(device)\n",
        "    batch_size = labels.size(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_preds = student_model(images)\n",
        "        \n",
        "    preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
        "    valid_labels.append(labels.to('cpu').numpy())\n",
        "\n",
        "predictions = np.concatenate(preds)\n",
        "valid_labels = np.concatenate(valid_labels)\n",
        "\n",
        "# Get the score\n",
        "score = accuracy_score(valid_labels, predictions.argmax(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "37M65nLWlVUN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c20c3092c0956f53c057234954b0e6e2beb63c056f97db512353abbe859d97b3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
