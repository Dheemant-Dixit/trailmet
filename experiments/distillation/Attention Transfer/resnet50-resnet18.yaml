DISTILL_ARGS : #hyperparameters for distillation process
  BETA : 500 #weight of factor loss
  EPOCHS : 5 #total number of epochs
  LR : 0.1 #learning rate
  WEIGHT_DECAY : 0.0005 #weight decay
  MILESTONES : [82, 123] #list of epoch milstones indices for scheduler
  GAMMA : 0.1 #multiplicative factor of learning rate decay
  TEACHER_LAYER_NAMES : ['layer1', 'layer2', 'layer3', 'layer4'] #names of teacher layer
  STUDENT_LAYER_NAMES : ['layer1', 'layer2', 'layer3', 'layer4'] #names of student layer
  VERBOSE : TRUE #verbose - whether to print while training

log_dir : at_resnet50-resnet18 #checkpoints directory and model name
cuda_id : 0 #device to be used